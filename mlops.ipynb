{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Деплой ML моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Какие варианты инференса ml моделей ты знаешь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под выводом понимается процесс использования обученной модели машинного обучения (ML) для принятия прогнозов или решений на основе новых входных данных. В зависимости от конкретного случая использования существует несколько вариантов вывода модели ML, каждый из которых оптимизирован для различных сценариев. Вот основные типы:\n",
    "\n",
    " 1. **Batch inference (пакетный вывод)**:\n",
    "   - **Определение**: Пакетный вывод подразумевает выполнение вывода на большом наборе данных одновременно, а не прогнозирование по одному.\n",
    "   - Пример использования**: Применяется для автономной обработки, когда прогнозы не должны выполняться в режиме реального времени, например, при генерации прогнозов на ночь или при массовой обработке данных для составления отчетов.\n",
    "   - **Преимущества**: \n",
    "     - Эффективность при обработке больших объемов данных.\n",
    "     - Можно оптимизировать пропускную способность, снизив накладные расходы на загрузку и инициализацию модели.\n",
    "   - **Недостатки**:\n",
    "     - Не подходит для систем реального времени.\n",
    "   - **Пример**: Прогнозирование оттока всех клиентов в конце каждого дня.\n",
    "\n",
    " 2. **Real-time inference**.\n",
    "   - **Определение**: Выводы в реальном времени обеспечивают предсказания сразу после получения новых данных. Модель должна реагировать быстро, обычно с низкой задержкой.\n",
    "   - Пример использования**: Идеально подходит для приложений, в которых решения должны приниматься мгновенно, например для обнаружения мошенничества, рекомендательных систем или чат-ботов.\n",
    "   - **Преимущества**:\n",
    "     - Мгновенная реакция на новые данные.\n",
    "   - **Недостатки**:\n",
    "     - Может потребовать оптимизации для достижения низкой задержки.\n",
    "     - При одновременном поступлении большого количества запросов может возникнуть проблема масштабируемости.\n",
    "   - Пример**: Система рекомендаций, предоставляющая персонализированные рекомендации по товарам, которые пользователи просматривают на сайте электронной коммерции.\n",
    "\n",
    " 3. **Streaming inference**\n",
    "   - **Определение**: Потоковое умозаключение непрерывно обрабатывает и делает прогнозы на основе потоков данных в реальном времени по мере их поступления.\n",
    "   - **Пример использования**: Подходит для чувствительных ко времени приложений, в которые поступает постоянный поток данных, таких как IoT-устройства, мониторинг в реальном времени или обнаружение аномалий в данных датчиков в реальном времени.\n",
    "   - **Преимущества**:\n",
    "     - Непрерывный вывод на лету.\n",
    "   - **Недостатки**:\n",
    "     - Сложность реализации и масштабирования для высокопроизводительных потоков данных.\n",
    "   - **Пример**: Мониторинг цен на акции для выявления аномального поведения рынка в реальном времени.\n",
    "\n",
    " 4. **On-Device or Edge Inference**\n",
    "   - **Определение**: В этом сценарии модель развертывается непосредственно на  устройствах (например, мобильных телефонах, устройствах IoT), а выводы делаются локально.\n",
    "   - Пример использования**: Используется, когда задержка в сети или конфиденциальность вызывают озабоченность, или когда приложение требует децентрализованной обработки (например, умные камеры, автономные транспортные средства).\n",
    "   - **Преимущества**:\n",
    "     - Низкая задержка и меньшая зависимость от подключения к Интернету.\n",
    "     - Сохранение конфиденциальности пользователей за счет локальной обработки данных.\n",
    "   - **Недостатки**:\n",
    "     - Ограниченные вычислительные ресурсы устройств могут потребовать уменьшения размера и сложности модели.\n",
    "   - **Пример**: Распознавание лиц на смартфоне без отправки данных в облако.\n",
    "\n",
    " 5. **Cloud inference**\n",
    "   - **Определение**: Выводы делаются на мощных облачных серверах, что позволяет модели масштабироваться и обслуживать множество запросов от разных пользователей или устройств.\n",
    "   - Пример использования**: Подходит для централизованной обработки данных из нескольких источников, где требуется масштабируемость и гибкость.\n",
    "   - **Преимущества**:\n",
    "     - Легко масштабируется и позволяет запускать большие и сложные модели.\n",
    "   - **Недостатки**:\n",
    "     - Может создавать сетевые задержки.\n",
    "     - Проблемы с конфиденциальностью данных, если конфиденциальные данные обрабатываются в облаке.\n",
    "   - **Пример**: Запуск большой трансформаторной модели типа GPT-4 для генерации текста.\n",
    "\n",
    " 6. **Distrubuted inference**\n",
    "   - **Определение**: При распределенном выводе рабочая нагрузка распределяется между несколькими серверами или устройствами, что позволяет параллельно обрабатывать задачи вывода.\n",
    "   - Пример использования**: Необходим для очень больших моделей или огромных объемов данных, когда одна машина не может справиться с нагрузкой.\n",
    "   - **Преимущества**:\n",
    "     - Позволяет масштабировать сложные модели (например, LLM) на нескольких машинах.\n",
    "     - Эффективно обрабатывает большие объемы запросов.\n",
    "   - **Недостатки**:\n",
    "     - Требуется сложная оркестровка и связь между распределенными системами.\n",
    "   - **Пример**: Обслуживание языковой модели с несколькими миллиардами параметров путем распределения ее частей между несколькими графическими процессорами или машинами.\n",
    "\n",
    " 7. **Hybrid inference**\n",
    "   - **Определение**: Комбинирует различные типы стратегий вывода в зависимости от ситуации. Например, можно сочетать вывод в реальном времени для чувствительных к времени данных и пакетный вывод для несрочных задач.\n",
    "   - **Случай использования**: Используется в системах, где различные задачи требуют разного уровня оперативности и вычислительной нагрузки.\n",
    "   - **Преимущества**:\n",
    "     - Гибкость и оптимизация под различные нужды.\n",
    "   - **Недостатки**:\n",
    "     - Более сложная реализация и управление.\n",
    "   - **Пример**: Приложение, в котором обнаружение мошенничества в реальном времени происходит одновременно с пакетным прогнозированием поведения пользователей в маркетинговых целях.\n",
    "\n",
    "\n",
    " 8. **Бессерверный вывод**\n",
    "   - **Определение**: Использование бессерверных архитектур, таких как AWS Lambda, для вывода моделей. Этот подход динамически распределяет ресурсы по мере необходимости, увеличивая или уменьшая их в зависимости от спроса.\n",
    "   - Пример использования**: Идеально подходит для легких моделей со спорадической нагрузкой, где важны масштабируемость и экономичность.\n",
    "   - **Преимущества**:\n",
    "     - Автоматическое масштабирование в зависимости от спроса.\n",
    "     - Нет необходимости управлять инфраструктурой.\n",
    "   - **Недостатки**:\n",
    "     - Проблемы с холодным стартом могут привести к задержкам при нечастых запросах.\n",
    "   - **Пример**: Запуск умозаключений на небольших задачах, таких как классификация изображений, загруженных пользователями в приложение для обмена фотографиями.\n",
    "\n",
    " 9. **Quantized inference**\n",
    "   - **Определение**: Квантование снижает точность параметров модели (например, с 32-битных плавающих чисел до 8-битных целых), чтобы сделать модель меньше и быстрее, не жертвуя при этом большой точностью.\n",
    "   - **Случай использования**: Оптимизирован для пограничных устройств или сценариев, в которых скорость вывода и эффективность использования памяти имеют решающее значение.\n",
    "   - **Преимущества**:\n",
    "     - Меньший объем памяти и более быстрые выводы.\n",
    "   - **Недостатки**:\n",
    "     - Некоторая потеря точности в зависимости от метода квантования.\n",
    "   - **Пример**: Развертывание квантованной нейронной сети на мобильном телефоне для обнаружения объектов.\n",
    "\n",
    " 10. **Мультимодальный вывод**\n",
    "   - **Определение**: Вывод с помощью моделей, которые одновременно обрабатывают несколько типов входных данных (например, текст, изображения, звук).\n",
    "   - Пример использования**: Применяется в сложных приложениях, где необходимо обрабатывать входные данные, поступающие от нескольких модальностей, например, для понимания видео или голосовых помощников.\n",
    "   - **Преимущества**:\n",
    "     - Работает с большим количеством входных данных.\n",
    "   - Недостатки**:\n",
    "     - Высокая вычислительная сложность и требовательность к ресурсам.\n",
    "   - **Пример**: ИИ-ассистент, обрабатывающий как голосовые команды, так и визуальный ввод с камеры.\n",
    "\n",
    "Эти варианты позволяют оптимизировать вывод модели в зависимости от таких ограничений, как задержка, масштаб, аппаратное обеспечение и сложность сценария использования.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что такок feature store?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Store** — это специализированное хранилище для управления признаками (features) машинного обучения, которое автоматизирует процесс создания, хранения, повторного использования и доставки признаков в модели ML. Это ключевой компонент в MLOps, который решает задачу управления признаками на всех этапах жизненного цикла ML модели.\n",
    "\n",
    "**Основные задачи Feature Store:**\n",
    "1. **Хранение признаков**:\n",
    "   - Feature Store позволяет хранить как статические, так и динамические признаки, чтобы они могли быть использованы повторно для разных моделей и экспериментов. Это помогает избежать необходимости создавать одни и те же признаки несколько раз для разных проектов.\n",
    "\n",
    "2. **Повторное использование признаков**:\n",
    "   - Повторное использование признаков, уже рассчитанных для одной модели, значительно ускоряет разработку новых моделей, снижает вычислительные затраты и уменьшает риск ошибок.\n",
    "\n",
    "3. **Обеспечение консистентности признаков**:\n",
    "   - Feature Store гарантирует, что признаки, используемые для обучения моделей, и признаки, подаваемые на модели в продакшн (в реальном времени), остаются согласованными. Это помогает предотвратить такие проблемы, как \"training-serving skew\" (расхождение признаков между обучением и продакшеном).\n",
    "\n",
    "4. **Управление версионированием признаков**:\n",
    "   - Как и модели, признаки также могут изменяться со временем. Feature Store помогает отслеживать версии признаков, обеспечивая воспроизводимость экспериментов и возможность вернуться к старым версиям признаков при необходимости.\n",
    "\n",
    "5. **Поддержка работы в реальном времени**:\n",
    "   - Feature Store может быть интегрирован с потоковыми системами для обновления признаков в реальном времени, что особенно полезно для задач, связанных с онлайн-предсказаниями (например, рекомендации, прогнозы).\n",
    "\n",
    "**Для чего используется Feature Store:**\n",
    "1. **Повышение эффективности разработки**:\n",
    "   - Позволяет инженерам и аналитикам быстро находить, переиспользовать и комбинировать признаки для разных моделей, что ускоряет разработку новых решений и улучшает их качество.\n",
    "\n",
    "2. **Снижение дублирования работы**:\n",
    "   - Платформа централизует вычисление признаков, что исключает необходимость в каждом проекте заново рассчитывать одни и те же признаки.\n",
    "\n",
    "3. **Обеспечение согласованности между обучением и продакшн**:\n",
    "   - Feature Store позволяет избежать ситуаций, когда признаки для обучения моделей отличаются от тех, что поступают на вход модели в реальном времени.\n",
    "\n",
    "4. **Оптимизация вычислительных ресурсов**:\n",
    "   - Хранение вычисленных признаков снижает необходимость повторных затрат на их пересчёт, что экономит ресурсы.\n",
    "\n",
    "**В каких случаях используется Feature Store:**\n",
    "1. **Масштабные проекты с большим количеством моделей**:\n",
    "   - В компаниях, где разрабатывается множество моделей, и есть необходимость в стандартизации признаков, Feature Store упрощает управление и ускоряет разработку.\n",
    "\n",
    "2. **Онлайн предсказания**:\n",
    "   - Если модели работают в реальном времени и требуется быстрое обновление признаков, Feature Store обеспечивает низкую задержку при подаче новых данных в модели.\n",
    "\n",
    "3. **Автоматизация и мониторинг признаков**:\n",
    "   - Feature Store полезен, когда необходимо отслеживать изменения в признаках и их влияние на модели (например, в случае \"drift\" признаков).\n",
    "\n",
    "4. **Сложные проекты с большим количеством источников данных**:\n",
    "   - Когда признаки создаются из множества различных источников (базы данных, стриминговые системы), Feature Store помогает эффективно управлять этими признаками и поддерживать их в актуальном состоянии.\n",
    "\n",
    "**Примеры систем Feature Store:**\n",
    "- **Feast** — Open-source Feature Store, разработанный совместно Gojek и Google Cloud.\n",
    "- **Hopsworks** — платформа для ML, включающая в себя Feature Store.\n",
    "- **Databricks Feature Store** — интеграция с экосистемой Databricks для управления признаками.\n",
    "\n",
    "Feature Store становится неотъемлемым инструментом в контексте MLOps, так как упрощает работу с признаками, снижает ошибки и ускоряет развитие ML моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
